# SaS Supernus Human Protein Atlas Data Ingestion Pipeline

* Requirements:
  * Python 3.8+ 
  * Python libraries: configparser, csvkit, bs4
  * Docker 20.10+

* Copy `pipeline.conf.example` over `pipeline.conf`
* Adjust `hp_atlas_single_entry_downloads_limit` under section `downloads_source` (`-1` to download all the single entries) 
* Make sure the section `[data_paths]` contains the right paths to working directories for the HPA uncompressed files. The pipeline won't keep the downloaded compressed files.
* Run the pipeline with the command: `python3 main.py` (or Run the project in PyCharm)
* Check if the Docker container `human-protein-atlas-postgres` is running and the status is up with: `docker ps` 
* Once the Docker container is running, use following command to connect to the Postgres instance via psql: 
`docker exec -it human-protein-atlas-postgres psql -U atlas-admin -d human-protein-atlas` 

* A log file with the downloads information generated by the pipeline is stored under after the pipeline `./logs/latest_updates.json`